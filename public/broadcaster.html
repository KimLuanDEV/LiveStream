<!doctype html>
<html lang="vi">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Broadcaster - Livestream</title>
  <style>
    :root { color-scheme: dark; }
    body { font-family: system-ui, Segoe UI, Roboto, sans-serif; background:#0b1220; color:#e6f0ff; margin:0; padding:24px; }
    .row { display:flex; gap:12px; align-items:center; flex-wrap:wrap; }
    video { width: 640px; max-width:100%; background:#000; border-radius:12px; }
    button { padding:10px 16px; border:0; border-radius:10px; cursor:pointer; font-weight:600; }
    .start { background:#2ecc71; }
    .stop { background:#e74c3c; }
    .muted { background:#8e44ad; }
    .tag { background:#17203a; padding:6px 10px; border-radius:8px; font-size:12px; }
    #logs { background:#0e1730; border:1px solid #233056; border-radius:10px; padding:10px; font-family:ui-monospace, SFMono-Regular, Menlo, monospace; font-size:12px; max-height:200px; overflow:auto; }
    .warn { color:#f7d774 }
    .err { color:#ff8a8a }
    .ok { color:#8ff0a4 }
  </style>
</head>
<body>
  <h1>üé• Broadcaster</h1>

  <div class="row">
    <button id="btnStart" class="start" disabled>B·∫Øt ƒë·∫ßu ph√°t</button>
    <button id="btnStartNoAudio" class="muted" disabled>Ph√°t (kh√¥ng mic)</button>
    <button id="btnFlip" class="muted" disabled>ƒê·ªïi camera</button>
    <button id="btnStop" class="stop" disabled>D·ª´ng ph√°t</button>
    <span id="status" class="tag">ƒêang kh·ªüi t·∫°o‚Ä¶</span>
  </div>

  <p>
    <span id="secureHint" class="tag"></span>
  </p>

  <video id="preview" playsinline autoplay muted></video>

  <h3>Nh·∫≠t k√Ω</h3>
  <div id="logs"></div>

  <script>
    // ====== Helpers ======
    const $ = (id) => document.getElementById(id);
    function log(msg, cls="") {
      const d = new Date().toLocaleTimeString();
      const el = document.createElement("div");
      if (cls) el.className = cls;
      el.textContent = `[${d}] ${msg}`;
      $("logs").appendChild(el);
      $("logs").scrollTop = $("logs").scrollHeight;
      console.log(msg);
    }

    // ====== Secure context hint (HTTPS/localhost) ======
    const isSecure = location.protocol === "https:" || location.hostname === "localhost" || location.hostname === "127.0.0.1";
    $("secureHint").textContent = isSecure
      ? "‚úÖ Secure context OK (HTTPS/localhost)"
      : "‚ö†Ô∏è C·∫ßn ch·∫°y HTTPS ho·∫∑c localhost ƒë·ªÉ camera/mic ho·∫°t ƒë·ªông";

    // ====== WS setup ======
    const WS_URL = (location.protocol === 'https:' ? 'wss' : 'ws') + '://' + location.host;
    let ws;
    let wsOpen = false;
    let desiredFacing = "user";         // "user" (tr∆∞·ªõc) | "environment" (sau)
    let currentCamDeviceId = null;      // deviceId camera ƒëang d√πng (n·∫øu bi·∫øt)
 
function makeVideoConstraints({ facing, deviceId }) {
  // ∆Øu ti√™n deviceId n·∫øu c√≥; n·∫øu kh√¥ng, d√πng facingMode (h·ª£p di ƒë·ªông)
  if (deviceId) {
    return { video: { deviceId: { exact: deviceId } } };
  }
  if (facing) {
    return { video: { facingMode: { exact: facing } } };
  }
  // fallback m·ªÅm 720p
  return { video: { width: { ideal: 1280 }, height: { ideal: 720 } } };
}


    function setupWS() {
      ws = new WebSocket(WS_URL);

      ws.addEventListener("open", () => {
        wsOpen = true;
        $("status").textContent = "WS connected. S·∫µn s√†ng ph√°t.";
        $("btnStart").disabled = false;
        $("btnStartNoAudio").disabled = false;
        log("WebSocket: connected", "ok");
      });

      ws.addEventListener("close", (e) => {
        wsOpen = false;
        $("status").textContent = "WS disconnected";
        $("btnStart").disabled = true;
        $("btnStartNoAudio").disabled = true;
        log("WebSocket: closed", "warn");
      });

      ws.addEventListener("error", (e) => {
        log("WebSocket error (ki·ªÉm tra c·ªïng/Render/Vercel h·ªó tr·ª£ WS).", "err");
      });

      ws.addEventListener("message", async (ev) => {
        const msg = JSON.parse(ev.data);

        if (msg.type === "ack" && msg.role === "broadcaster") {
          log("Server ACK: broadcaster s·∫µn s√†ng.", "ok");
          $("status").textContent = "ƒêang ph√°t‚Ä¶ ch·ªù viewer";
        }

        if (msg.type === "viewer-join") {
          log(`Viewer join: ${msg.viewerId}`);
          createOfferForViewer(msg.viewerId);
        }

        if (msg.type === "answer") {
          const pc = peers.get(msg.viewerId);
          if (pc) {
            await pc.setRemoteDescription(new RTCSessionDescription(msg.sdp));
            log(`ƒê√£ nh·∫≠n answer t·ª´ viewer ${msg.viewerId}`, "ok");
          }
        }

        if (msg.type === "ice-candidate") {
          const pc = peers.get(msg.viewerId);
          if (pc && msg.candidate) {
            try { await pc.addIceCandidate(new RTCIceCandidate(msg.candidate)); } catch (e) { log("addIceCandidate error: " + e.message, "err"); }
          }
        }

        if (msg.type === "viewer-left") {
          const pc = peers.get(msg.viewerId);
          if (pc) {
            pc.close();
            peers.delete(msg.viewerId);
            log(`Viewer r·ªùi: ${msg.viewerId}`, "warn");
          }
        }

        if (msg.type === "end") {
          log("Server y√™u c·∫ßu d·ª´ng ph√°t (broadcaster c≈© ng·∫Øt).", "warn");
          stopStream();
        }
      });
    }

    // G·ªçi ngay
    setupWS();

    // ====== WebRTC ======
    const peers = new Map(); // viewerId -> RTCPeerConnection
    let localStream = null;
    let isStreaming = false;
    const iceServers = [
      { urls: "stun:stun.l.google.com:19302" },
      // N·∫øu c·∫ßn xuy√™n NAT t·ªët h∆°n, th√™m TURN ·ªü ƒë√¢y:
      // { urls: "turn:your.turn.server:3478", username: "user", credential: "pass" }
    ];

    async function ensureWSReady() {
      if (wsOpen) return true;
      for (let i=0;i<30;i++) { // ƒë·ª£i t·ªëi ƒëa ~3s
        await new Promise(r => setTimeout(r, 100));
        if (wsOpen) return true;
      }
      log("WS ch∆∞a s·∫µn s√†ng. Kh√¥ng th·ªÉ ph√°t.", "err");
      return false;
    }

    async function startStream(withAudio = true) {
      // 1) Ki·ªÉm tra WS
      const ok = await ensureWSReady();
      if (!ok) return;

      // 2) Xin thi·∫øt b·ªã
      try {
        const constraints = { video: { width: { ideal: 1280 }, height: { ideal: 720 } }, audio: withAudio };
        localStream = await navigator.mediaDevices.getUserMedia(constraints);
        $("preview").srcObject = localStream;
        log("ƒê√£ l·∫•y camera/mic.", "ok");
      } catch (e) {
        log("Kh√¥ng truy c·∫≠p ƒë∆∞·ª£c camera/mic: " + e.message, "err");
        $("status").textContent = "T·ª´ ch·ªëi camera/mic ho·∫∑c l·ªói thi·∫øt b·ªã.";
        return;
      }

      // 3) B√°o server: broadcaster s·∫µn s√†ng
      try {
        ws.send(JSON.stringify({ type: "broadcaster-ready" }));
      } catch (e) {
        log("G·ª≠i broadcaster-ready th·∫•t b·∫°i: " + e.message, "err");
        return;
      }

      isStreaming = true;
      $("btnFlip").disabled = false;
      $("btnStart").disabled = true;
      $("btnStartNoAudio").disabled = true;
      $("btnStop").disabled = false;
      $("status").textContent = "ƒêang ph√°t‚Ä¶ m·ªùi viewer m·ªü viewer.html";
    }

    async function createOfferForViewer(viewerId) {
      if (!localStream) {
        log("Ch∆∞a c√≥ localStream khi viewer join.", "err");
        return;
      }
      const pc = new RTCPeerConnection({ iceServers });
      peers.set(viewerId, pc);

      localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

      pc.onicecandidate = (e) => {
        if (e.candidate) {
          ws.send(JSON.stringify({
            type: "ice-candidate",
            from: "broadcaster",
            viewerId,
            candidate: e.candidate
          }));
        }
      };
      pc.onconnectionstatechange = () => {
        log(`Peer ${viewerId} state: ${pc.connectionState}`);
      };

      const offer = await pc.createOffer({ offerToReceiveAudio: false, offerToReceiveVideo: false });
      await pc.setLocalDescription(offer);

      ws.send(JSON.stringify({
        type: "offer",
        viewerId,
        sdp: pc.localDescription
      }));
      log(`ƒê√£ g·ª≠i offer cho viewer ${viewerId}`, "ok");
    }

    function stopStream() {
      if (!isStreaming) return;
      for (const [, pc] of peers) pc.close();
      peers.clear();
      if (localStream) localStream.getTracks().forEach(t => t.stop());
      localStream = null;
      isStreaming = false;
      $("btnFlip").disabled = true;
      $("preview").srcObject = null;
      $("btnStart").disabled = !wsOpen ? true : false;
      $("btnStartNoAudio").disabled = !wsOpen ? true : false;
      $("btnStop").disabled = true;
      $("status").textContent = "ƒê√£ d·ª´ng ph√°t";
      log("ƒê√£ d·ª´ng ph√°t v√† ƒë√≥ng m·ªçi peer.");
    }

    $("btnStart").onclick = () => startStream(true);
    $("btnStartNoAudio").onclick = () => startStream(false);
    $("btnStop").onclick = stopStream;

    // ====== Extra: ki·ªÉm tra thi·∫øt b·ªã s·∫µn c√≥ (g·ª£i √Ω debug) ======
    (async () => {
      try {
        const devices = await navigator.mediaDevices.enumerateDevices();
        const cams = devices.filter(d => d.kind === "videoinput").length;
        const mics = devices.filter(d => d.kind === "audioinput").length;
        log(`Thi·∫øt b·ªã: ${cams} camera, ${mics} mic.`);
      } catch {}
    })();


async function getCameras() {
  const devices = await navigator.mediaDevices.enumerateDevices();
  return devices.filter(d => d.kind === "videoinput");
}

async function switchCamera() {
  if (!isStreaming) {
    log("Ch∆∞a ph√°t. H√£y b·∫•m B·∫Øt ƒë·∫ßu ph√°t tr∆∞·ªõc khi ƒë·ªïi camera.", "warn");
    return;
  }

  try {
    // 1) Quy·∫øt ƒë·ªãnh facing ti·∫øp theo
    const nextFacing = desiredFacing === "user" ? "environment" : "user";

    // 2) Th·ª≠ map deviceId theo facing (n·∫øu c√≥ nhi·ªÅu camera)
    let targetDeviceId = null;
    try {
      const cams = await getCameras();
      // c·ªë g·∫Øng match theo label (sau khi c·∫•p quy·ªÅn, label s·∫Ω c√≥ ch·ªØ 'back'/'rear'/'front' ho·∫∑c n·ªôi ƒë·ªãa)
      const guess = cams.find(c =>
        (nextFacing === "environment")
          ? /back|rear|environment|sau|ngo√†i/i.test(c.label)
          : /front|user|tr∆∞·ªõc|trong/i.test(c.label)
      );
      if (guess) targetDeviceId = guess.deviceId;
    } catch { /* ignore */ }

    // 3) Xin track video m·ªõi theo deviceId (n·∫øu c√≥) ho·∫∑c facingMode
    const constraints = makeVideoConstraints({ facing: nextFacing, deviceId: targetDeviceId });
    const newStream = await navigator.mediaDevices.getUserMedia({
      ...constraints,
      audio: false // ch·ªâ c·∫ßn video track m·ªõi; audio gi·ªØ nguy√™n
    });
    const newVideoTrack = newStream.getVideoTracks()[0];
    if (!newVideoTrack) throw new Error("Kh√¥ng l·∫•y ƒë∆∞·ª£c video track m·ªõi.");

    // 4) G·∫Øn v√†o local preview
    // H·∫° track c≈©
    const oldVideoTracks = localStream.getVideoTracks();
    oldVideoTracks.forEach(t => t.stop());
    // Remove c≈© kh·ªèi localStream (n·∫øu tr√¨nh duy·ªát c·∫ßn)
    oldVideoTracks.forEach(t => localStream.removeTrack?.(t));

    // Th√™m track m·ªõi v√†o localStream
    localStream.addTrack(newVideoTrack);
    // C·∫≠p nh·∫≠t srcObject (ƒë·∫£m b·∫£o video ƒëang ch·∫°y)
    $("preview").srcObject = null;
    $("preview").srcObject = localStream;

    // 5) Thay track trong t·∫•t c·∫£ peer sender (kh√¥ng renegotiate)
    for (const [, pc] of peers) {
      const senders = pc.getSenders().filter(s => s.track && s.track.kind === "video");
      if (senders.length) {
        await Promise.all(senders.map(s => s.replaceTrack(newVideoTrack)));
      } else {
        // fallback hi·∫øm: ch∆∞a c√≥ sender video ‚Üí addTrack
        pc.addTrack(newVideoTrack, localStream);
      }
    }

    // 6) C·∫≠p nh·∫≠t tr·∫°ng th√°i & log
    desiredFacing = nextFacing;
    // Th·ª≠ ƒë·ªçc l·∫°i deviceId ƒëang ch·∫°y
    const settings = newVideoTrack.getSettings?.();
    currentCamDeviceId = settings?.deviceId || targetDeviceId || null;

    log(`ƒê√£ ƒë·ªïi camera sang: ${desiredFacing}${currentCamDeviceId ? " ("+currentCamDeviceId+")" : ""}`, "ok");
  } catch (e) {
    log("ƒê·ªïi camera th·∫•t b·∫°i: " + e.message, "err");
  }
}

$("btnFlip").onclick = switchCamera;


const baseConstraints = makeVideoConstraints({ facing: desiredFacing, deviceId: currentCamDeviceId });
const constraints = {
  ...baseConstraints,
  audio: withAudio
};
localStream = await navigator.mediaDevices.getUserMedia(constraints);

  </script>
</body>
</html>
